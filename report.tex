\documentclass[12pt]{report}

% Packages (keep sorted)
\usepackage{
    algorithm,      % For algorithm environment
    algpseudocode,  % For pseudocode
    hyperref,       % For PDF bookmarks
    listings,
}

% PDF bookmarks setup (keep sorted)
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
}

\lstset{mathescape,showstringspaces=false,breaklines=true,numbers=left,numbersep=5pt,numberstyle=\small,language=c}

\begin{document}

% Info section

% TODO(sanjay): come up with something more creative
\title{RTX Project Report}

\author{
    Craig, Shale\\
    20371384\\
    \texttt{sakcraig@uwaterloo.ca}
    \and
    Klen, Alex\\
    XXXXXXXX\\
    \texttt{XXXX@uwaterloo.ca}
    \and
    Menakuru, Sanjay\\
    20374915\\
    \texttt{smenakur@uwaterloo.ca}
    \and
    Wei, Jonathan\\
    XXXXXXXX\\
    \texttt{XXXX@uwaterloo.ca}
}

\maketitle

\begin{abstract}
    Here is our awesome abstract
\end{abstract}

\tableofcontents
\listofalgorithms

% NOTE(sanjay): uncomment these if we add any figures or tables
% \listoffigures
% \listoftables


\part{Introduction}

\part{Kernel Implementation}
% This part is at max 30 pages.

\chapter{Scheduler}
% Make sure to include pseudocode and testing, if appropriate.

\section{Description}
The scheduler is responsible for dividing processor time amongst all of the
system's processes. It handles context switching between processes, deciding
which process to schedule next, and preempting or blocking processes when
appropriate. Processes can be in one of the following states: new, ready,
running, blocked on memory, blocked on message, unused. New is a state that
processes are given after being initialized so that the scheduler can properly
context switch to them for the first time. The running state signifies that the
process is the only currently running process in the system. Processes which
are ready are placed in a priority queue, and the scheduler will select the
ready process with the highest priority to run next. Processes which are
blocked on memory are put into another priority queue, and when memory is
freed, the blocked process with the highest priority is unblocked. If the
unblocked process has a higher priority than the currently running process, then
the currently running process is preempted. Processes that are blocked on a
message remain blocked until they are sent a message. Upon receiving a message,
the process is unblocked, and if it has a higher priority than the sending
process, the sending process is preempted.

The ready queue is a priority queue implemented with a heap. We decided to use a
priority queue for all ready/blocked processes instead of a queue for each
priority level because that way we could support an arbitrary number of
priorities in the system without having our runtime depend on the number of
priorities.

Following is pseudo-code for process initialization:
\begin{lstlisting}
function k_initProcesses()
    Initialize process-ready queue
    Initialize blocked-on-memory queue

    for each process p, index i:
        p.pid = i
        // Use three memory blocks for each process stack and place stack pointer at end of third one
        p.stack = acquireMemoryBlock() three times + memory block size 
        push initial required values onto stack
        set p.startLocation to appropriate process function location
        p.debugEnvelope = acquireMemoryBlock() // Reserve a debug envelope for each process to be able to display a debug message even if there is no free memory in the system
        p.state = new
        add p to the process-ready queue

    Initialize CRT proc
\end{lstlisting}

Following is pseudo\-code for the kernel\-level function for release\_processor.
This is called any time the current process should be preempted and a new
process should be scheduled. The function takes a parameter that specifies what
the reason is for the context\-switch. The release reason can be one of the
following: a voluntary yield, a process priority change, memory was freed, the
system is out of memory, a message was sent, or a message was received. The
scheduling behavior can be different for some of these reasons.

\begin{lstlisting}
function k_releaseProcessor(releaseReason)
    // First we process the changed states of a few interrupt-driven systems
    here to avoid ISRs modifying kernel state while they are interrupting
    kernel methods.
    k_processUartOutput()
    k_processUartInput()
    k_processDelayedMessages()

    // We need to set these three variables depending on the release reason
    define targetState, // The state the currently running process should get
        srcQueue, // The queue we should use to schedule the next process
        dstQueue // The queue we should add the currently running process to.

    if releaseReason == out of memory:
        srcQueue = process-ready queue
        dstQueue = blocked-on-memory queue
        targetState = blocked on memory
    else if releaseReason == message was received
        if the current process's mail queue is empty:
            srcQueue = process-ready queue
            dstQueue = NULL // Don't place in any queue
            targetState = blocked on message
        else:
            srcQueue = process-ready queue
            dstQueue = process-ready queue
            targetState = ready
    else:
        srcQueue = process-ready queue
        dstQueue = process-ready queue
        targetState = ready

        // Keep the null process out of the ready queue - handle it seperately
        if currentProcess is the null process:
            dstQueue = NULL

    if srcQueue is not NULL and srcQueue.size > 0:
        nextProc = srcQueue.pop()
    else:
        nextProc = the null process

    if currentProcess is not NULL:
        // Save old process info
        currentProcess.stack = getStackPointer()
        currentProcess.state = targetState;
        if dstQueue is not NULL:
            dstQueue.add(currentProcess)

    oldState = nextProc.state
    nextProc.state = running
    currentProcess = nextProc
    setStackPointer(nextProc.stack)
    if oldState == new:
        __rte() // If first time, we have to pop the exception stack frame so we call this assembly instruction
\end{lstlisting}

\section{Running Time Analysis}
The runtime for k\_initProcesses is $O(nlogn)$, where n is the number of
processes in the system. This is because for each of n processes we insert them
into the process\-ready queue, which is implemented as a heap and therefore
taking $O(logn)$ to insert an element. This function could be trivially
modified to achieve a runtime of $O(n)$ time, by putting all of the heap
elements in an array first, and then heapifying it afterwards, but since there
is a small, fixed number of processes in the system we didn't bother completing
this optimization since this function only runs once at system startup.

The runtime for k\_releaseProcessor, with the assumption that the UART and
delayed message processing at the beginning will typically take $O(1)$ time,
takes $O(log n)$ time, where n is the number of processes in the system. It is
bounded by removing and inserting from the source and destination priority
queues (heaps). This provides good performance, and we can have an arbitrary
number of priorities in the system because a priority queue was used instead of
a queue per priority level.

\chapter{Memory Allocator}
% Make sure to include pseudocode and testing, if appropriate.

\section{Description}
    The memory allocator was designed with two orthogonal layers. The first is
    called the `block layer', and is responsible for allocating and deallocating
    blocks at a low level. The second is called the `metadata layer'; this layer
    builds upon the work done by the block layer, and adds the ability to store
    metadata about blocks. We will describe both of these layers independently.

\subsection{Block Layer}
    The block layer has a conceptually simple role. It is responsible for
    managing a pool of contiguous memory. Given a start memory address, an
    end memory address, and a block size, the block
    layer must provide two pieces of functionality. It must support allocating
    a block from the pool, and it must support freeing a block back into the
    pool. One design constraint is that it must prefer reusing a previously
    allocated block that has been freed, rather than handing out a block that
    has never been allocated before. The reason for this constraint will
    become clear when discussing the metadata layer.

    See Algorithm \ref{code:mem_block} for a pseudocode implementation of this
    layer. Note that this layer returns an error code when it runs out of
    memory. Further, this layer does some rudimentary sanity checking but
    doesn't handle some obvious error conditions. For example, this layer allows
    blocks to be inserted into the free list twice (assuming a trivial linked
    list implementation). This is not an error; it is the responsibility of
    the metadata layer to never allow this to happen. Finally, it is important
    to point out that this layer automatically zeroes memory. This is slightly
    detrimental to performance, but allows user processes to use binary
    comparisons between structs without caring about garbage in the struct's
    padding. We deemed this convenience worth the slight performance overhead.

    \begin{algorithm}
        \caption{Block layer pseudocode}
        \label{code:mem_block}
        \begin{algorithmic}[1]

            \State $blockSize \gets 2^7$
            \Comment{Blocksize in bytes (configurable)}

            \State $startAddr \gets 0$
            \Comment{Start address of pool (inclusive)}

            \State $endAddr \gets 2^{16}$
            \Comment{End address of pool (exclusive)}

            \State $nextAddr \gets startAddr$
            \Comment{Next available address in pool}

            \State $freeList \gets \{\}$
            \Comment{List of freed blocks}\\

            \Function{alloc\_block}{$ $}
                \If {$|freeList| > 0$} \Comment{Check free-list}
                    \State $blk \gets freeList[0]$
                    \State $freeList = freeList - \{blk\}$
                    \State \Call{zero}{$blk$}
                    \State \Return $blk$
                \EndIf\\

                \If {$nextAddr + blockSize >= endAddr$}
                    \Comment{Out-of-memory}
                    \State \Return $-1$
                \EndIf\\

                \State $blk \gets nextAddr$
                \State $nextAddr \gets nextAddr + blockSize$
                \State \Call{zero}{$blk$}
                \State \Return $blk$
            \EndFunction\\
            \Function{free\_block}{$blk$}
                \If {$blk < startAddr \vee nextAddr <= blk \vee endAddr <= blk$}
                    \State \Return \Comment{Outside valid range}
                \EndIf\\

                \If {$blk - startAddr \not\equiv 0 \bmod{blockSize}$}
                    \State \Return \Comment{Unaligned}
                \EndIf\\

                \State $freeList = freeList \cup \{blk\}$
            \EndFunction
        \end{algorithmic}
    \end{algorithm}


\subsection{Metadata Layer}
    The metadata layer builds atop the block layer, and adds the ability for the
    allocator to store metadata about blocks. Since it is built upon the block
    layer, it must fit its metadata storage in blocks. To avoid a costly setup
    phase, the metadata layer uses a lazy, arena-based storage scheme. The
    general version of the metadata layer supports an arbitrary amount of
    metadata per block ranging from some non-zero amount of metadata to half the
    block size worth of metadata.

    For the sake of description, let us call the number of metadata fields that
    fit inside a block $k$. That is to say, one block can hold the metadata for
    $k$ blocks. The metadata layer discriminates between two types of blocks,
    data blocks and arena header blocks. The metadata layer implements a
    function that takes a block and returns its associated arena header block.
    For our purposes, this function acts as the identity function when passed
    an arena header block. These definitions lead to the notion that an arena
    header block is responsible for storing the metadata of itself, as well as
    the following $k-1$ blocks. The metadata layer is responsible for serving
    the user-facing API.

    See Algorithm \ref{code:mem_meta} for a pseudocode implementation of this
    layer. Note that this layer can also access the variables defined by the
    block layer (they can be found in Algorithm \ref{code:mem_block}). Also note that we have elided the code of several trivial helper functions. For
    example, we did not specify the body of the `get\_header' function. Since
    the implementation of this function was some simple modular arithmetic, we
    did not feel it was worth wasting the reader's time with such minutiae.

    While the metadata layer is parameterized on $k$, for our actual
    implementation, we chose $k$ to be equal to our block size; this implies
    the metadata for each process fits inside 1 byte. Indeed, we stored the
    owner pid of each block as the only metadata, and the bitwidth of the pid
    type in our system was 8.

    \begin{algorithm}
        \caption{Metadata layer pseudocode}
        \label{code:mem_meta}
        \begin{algorithmic}[1]

            \State $k \gets 2^7$
            \Comment{Blocks per arena (configurable)}

            \State $arenaSize \gets k * blockSize$
            \Comment{Arena size (in bytes)}

            \Function{request\_memory\_block}{$pid$}
                \State $header \gets -1$
                \State $blk \gets -1$ \\

                \State $blk \gets \Call{alloc\_block}{ }$
                \If {$blk = -1$}
                    \State \Return $-1$
                \EndIf\\

                \State $header \gets \Call{get\_header}{blk}$
                \If {$blk = header$}
                    \State $blk \gets \Call{alloc\_block}{ }$
                \EndIf\\

                \If {$blk = -1$}
                    \State \Return $-1$
                \EndIf\\

                \State \Call{set\_owner}{$header, blk, pid$}
                \State \Return $blk$
            \EndFunction\\
            \Function{free\_memory\_block}{$blk, pid$}
                \State $header \gets \Call{get\_header}{blk}$
                \If {$header = -1$}
                    \State \Return $-1$
                \EndIf\\

                \If {$ \neg \Call{is\_owner}{header, blk, pid}$}
                    \State \Return $-1$
                \EndIf\\

                \State \Call{set\_owner}{$header, blk, 0$}
                \State \Call{free\_block}{$blk$}
            \EndFunction
        \end{algorithmic}
    \end{algorithm}


\section{Theoretical Analysis}
    Both layers were carefully designed to be $O(1)$ for all operations. This
    should be trivial by inspection, as all the functions do a tiny amount of
    arithmetic, and considering we used a linked-list as the implementation of
    the free list.

    A slightly more interesting analysis is the space overhead of our metadata
    scheme. The metadata layer uses $\frac{k-1}{k}$ blocks for storing user
    data; this yields a storage overhead of $\frac{1}{k}$. For our
    implementation, we picked $k=2^7$, yielding an overhead of $0.78\%$, or a
    utilization rate of $99.22\%$.

\section{Measurements}
    % TODO(sanjay): do some measurements

\chapter{Message Passing}
% Make sure to include pseudocode and testing, if appropriate.

\section{Description}

\section{Running Time Analysis}

\section{Measurements}

\chapter{I/O}
% Make sure to include pseudocode and testing, if appropriate.

\section{UART output}

\section{UART input}

\chapter{Misc}
% Make sure to include pseudocode and testing, if appropriate.

\section{Bridge Layer}

\part{User-level Processes}

\chapter{Proc 1}

\chapter{Proc 2}

\part{Lessons Learned}
% They call this the lessons learned summary.
% 1-2 pages
% what you did do well, both technically and organizationally, and what you
% would do differently if you were to do it again

\end{document}
