\documentclass[12pt]{report}

% Packages (keep sorted)
\usepackage{
    algorithm,      % For algorithm environment
    algpseudocode,  % For pseudocode
    hyperref,       % For PDF bookmarks
    tikz,           % For state diagrams
}

% State diagrams (i.e. I/O)
\usetikzlibrary{
    shadows,
    positioning,
}
% TODO: move these to another file.
\tikzstyle{block} = [rectangle, draw,
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw]
\tikzstyle{cloud} = [draw, rectangle, node distance=3cm,
    minimum height=2em]

% PDF bookmarks setup (keep sorted)
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
}

\begin{document}

% Info section

% TODO(sanjay): come up with something more creative
\title{RTX Project Report}

\author{
    Craig, Shale\\
    20371384\\
    \texttt{sakcraig@uwaterloo.ca}
    \and
    Klen, Alex\\
    XXXXXXXX\\
    \texttt{XXXX@uwaterloo.ca}
    \and
    Menakuru, Sanjay\\
    20374915\\
    \texttt{smenakur@uwaterloo.ca}
    \and
    Wei, Jonathan\\
    XXXXXXXX\\
    \texttt{XXXX@uwaterloo.ca}
}

\maketitle

\begin{abstract}
    Here is our awesome abstract
\end{abstract}

\tableofcontents
\listofalgorithms
\listoffigures

% NOTE(sanjay): uncomment these if we add any figures or tables
% \listoftables


\part{Introduction}

\part{Kernel Implementation}
% This part is at max 30 pages.

\chapter{Scheduler}
% Make sure to include pseudocode and testing, if appropriate.

\section{Description}

\section{Running Time Analysis}

\chapter{Memory Allocator}
% Make sure to include pseudocode and testing, if appropriate.

\section{Description}
    The memory allocator was designed with two orthogonal layers. The first is
    called the `block layer', and is responsible for allocating and deallocating
    blocks at a low level. The second is called the `metadata layer'; this layer
    builds upon the work done by the block layer, and adds the ability to store
    metadata about blocks. We will describe both of these layers independently.

\subsection{Block Layer}
    The block layer has a conceptually simple role. It is responsible for
    managing a pool of contiguous memory. Given a start memory address, an
    end memory address, and a block size, the block
    layer must provide two pieces of functionality. It must support allocating
    a block from the pool, and it must support freeing a block back into the
    pool. One design constraint is that it must prefer reusing a previously
    allocated block that has been freed, rather than handing out a block that
    has never been allocated before. The reason for this constraint will
    become clear when discussing the metadata layer.

    See Algorithm \ref{code:mem_block} for a pseudocode implementation of this
    layer. Note that this layer returns an error code when it runs out of
    memory. Further, this layer does some rudimentary sanity checking but
    doesn't handle some obvious error conditions. For example, this layer allows
    blocks to be inserted into the free list twice (assuming a trivial linked
    list implementation). This is not an error; it is the responsibility of
    the metadata layer to never allow this to happen. Finally, it is important
    to point out that this layer automatically zeroes memory. This is slightly
    detrimental to performance, but allows user processes to use binary
    comparisons between structs without caring about garbage in the struct's
    padding. We deemed this convenience worth the slight performance overhead.

    \begin{algorithm}
        \caption{Block layer pseudocode}
        \label{code:mem_block}
        \begin{algorithmic}[1]

            \State $blockSize \gets 2^7$
            \Comment{Blocksize in bytes (configurable)}

            \State $startAddr \gets 0$
            \Comment{Start address of pool (inclusive)}

            \State $endAddr \gets 2^{16}$
            \Comment{End address of pool (exclusive)}

            \State $nextAddr \gets startAddr$
            \Comment{Next available address in pool}

            \State $freeList \gets \{\}$
            \Comment{List of freed blocks}\\

            \Function{alloc\_block}{$ $}
                \If {$|freeList| > 0$} \Comment{Check free-list}
                    \State $blk \gets freeList[0]$
                    \State $freeList = freeList - \{blk\}$
                    \State \Call{zero}{$blk$}
                    \State \Return $blk$
                \EndIf\\

                \If {$nextAddr + blockSize >= endAddr$}
                    \Comment{Out-of-memory}
                    \State \Return $-1$
                \EndIf\\

                \State $blk \gets nextAddr$
                \State $nextAddr \gets nextAddr + blockSize$
                \State \Call{zero}{$blk$}
                \State \Return $blk$
            \EndFunction\\
            \Function{free\_block}{$blk$}
                \If {$blk < startAddr \vee nextAddr <= blk \vee endAddr <= blk$}
                    \State \Return \Comment{Outside valid range}
                \EndIf\\

                \If {$blk - startAddr \not\equiv 0 \bmod{blockSize}$}
                    \State \Return \Comment{Unaligned}
                \EndIf\\

                \State $freeList = freeList \cup \{blk\}$
            \EndFunction
        \end{algorithmic}
    \end{algorithm}


\subsection{Metadata Layer}
    The metadata layer builds atop the block layer, and adds the ability for the
    allocator to store metadata about blocks. Since it is built upon the block
    layer, it must fit its metadata storage in blocks. To avoid a costly setup
    phase, the metadata layer uses a lazy, arena-based storage scheme. The
    general version of the metadata layer supports an arbitrary amount of
    metadata per block ranging from some non-zero amount of metadata to half the
    block size worth of metadata.

    For the sake of description, let us call the number of metadata fields that
    fit inside a block $k$. That is to say, one block can hold the metadata for
    $k$ blocks. The metadata layer discriminates between two types of blocks,
    data blocks and arena header blocks. The metadata layer implements a
    function that takes a block and returns its associated arena header block.
    For our purposes, this function acts as the identity function when passed
    an arena header block. These definitions lead to the notion that an arena
    header block is responsible for storing the metadata of itself, as well as
    the following $k-1$ blocks. The metadata layer is responsible for serving
    the user-facing API.

    See Algorithm \ref{code:mem_meta} for a pseudocode implementation of this
    layer. Note that this layer can also access the variables defined by the
    block layer (they can be found in Algorithm \ref{code:mem_block}). Also note that we have elided the code of several trivial helper functions. For
    example, we did not specify the body of the `get\_header' function. Since
    the implementation of this function was some simple modular arithmetic, we
    did not feel it was worth wasting the reader's time with such minutiae.

    While the metadata layer is parameterized on $k$, for our actual
    implementation, we chose $k$ to be equal to our block size; this implies
    the metadata for each process fits inside 1 byte. Indeed, we stored the
    owner pid of each block as the only metadata, and the bitwidth of the pid
    type in our system was 8.

    \begin{algorithm}
        \caption{Metadata layer pseudocode}
        \label{code:mem_meta}
        \begin{algorithmic}[1]

            \State $k \gets 2^7$
            \Comment{Blocks per arena (configurable)}

            \State $arenaSize \gets k * blockSize$
            \Comment{Arena size (in bytes)}

            \Function{request\_memory\_block}{$pid$}
                \State $header \gets -1$
                \State $blk \gets -1$ \\

                \State $blk \gets \Call{alloc\_block}{ }$
                \If {$blk = -1$}
                    \State \Return $-1$
                \EndIf\\

                \State $header \gets \Call{get\_header}{blk}$
                \If {$blk = header$}
                    \State $blk \gets \Call{alloc\_block}{ }$
                \EndIf\\

                \If {$blk = -1$}
                    \State \Return $-1$
                \EndIf\\

                \State \Call{set\_owner}{$header, blk, pid$}
                \State \Return $blk$
            \EndFunction\\
            \Function{free\_memory\_block}{$blk, pid$}
                \State $header \gets \Call{get\_header}{blk}$
                \If {$header = -1$}
                    \State \Return $-1$
                \EndIf\\

                \If {$ \neg \Call{is\_owner}{header, blk, pid}$}
                    \State \Return $-1$
                \EndIf\\

                \State \Call{set\_owner}{$header, blk, 0$}
                \State \Call{free\_block}{$blk$}
            \EndFunction
        \end{algorithmic}
    \end{algorithm}


\section{Theoretical Analysis}
    Both layers were carefully designed to be $O(1)$ for all operations. This
    should be trivial by inspection, as all the functions do a tiny amount of
    arithmetic, and considering we used a linked-list as the implementation of
    the free list.

    A slightly more interesting analysis is the space overhead of our metadata
    scheme. The metadata layer uses $\frac{k-1}{k}$ blocks for storing user
    data; this yields a storage overhead of $\frac{1}{k}$. For our
    implementation, we picked $k=2^7$, yielding an overhead of $0.78\%$, or a
    utilization rate of $99.22\%$.

\section{Measurements}
    % TODO(sanjay): do some measurements

\chapter{Message Passing}
% Make sure to include pseudocode and testing, if appropriate.

\section{Description}

\section{Running Time Analysis}

\section{Measurements}

\chapter{I/O}
% Make sure to include pseudocode and testing, if appropriate.

    I/O interactions were designed to provide a simple user-facing interface
    while guaranteeing a high level of functionality and speed in low-memory
    situations. Functionality was split between separate input and output
    processes, each of which were responsible for providing their respective
    functionality. By separating functionality, we were able to take advantage
    of the benefits of microkernel architecture instead of monolithic
    architecture.
    In the context of our OS, both input and output tasks consisted of % TODO: should I put our OS name here?
    interacting solely with UART (Universal Asynchronous Receiver / Transmitter)
    connections to the boards used in this lab.
    We will describe both input and output independently in their respective
    sections.

\section{Input}
\label{sec:Input}
    In this assignment, the primary input device is keyboard input.
    Keyboard input triggers the UART0\_IRQHandler assembly interrupt. This
    passes the input to the c\_UART0\_IRQHandler method that puts the events
    in a buffer. Whenever release\_processor is called, messages in the
    buffer are sent to the keyboard decoder method to decode the new
    events in the buffer. In the case that input is a hot-key,
    it immediately executes the relevant execution path. In the case that input
    is a complete command, a process that has registered for that command will
    receive a message containing the command. If no processes have been
    registered, the message is freed.

    Figure \ref{figure:inputDiagram} illustrates this process in a visually
    apparent manner, and Algorithm \ref{code:uart_input} expresses this flow
    algorithmically.

    \begin{figure}
        \centering
        \label{figure:inputDiagram}
        \caption{Flow of Input Data to User Processes}
        \begin{tikzpicture}[node distance = 3cm,
                            auto]
            % Place nodes
            \node [block] (kbd) {keyboard};
            \node [cloud, above of=kbd] (user) {user};
            \node [block, right of=kbd] (uart_h) {IRQHandler};
            \node [cloud, above right of=uart_h] (buffer) {buffer};
            \node [block, right of=uart_h] (kcd) {keyboard decoder};
            \node [block, below of=kcd] (release) {release processor};
            \node [cloud, right of=kcd] (message) {message};
            \node [block, right of=message] (keyboard_proc) {keyboard process};
            \node [block, below of=keyboard_proc] (user_proc) {user processes};
            % Draw edges
            \path [->,very thick,line,dashed] (user) -- (kbd);
            \path [->,very thick,line] (kbd) -- (uart_h);
            \path [->,very thick,line,dashed] (uart_h) -- (buffer);
            \path [->,very thick,line] (release) -- (kcd);
            \path [very thick,line] (kcd) -- (message);
            \path [->,very thick,line] (message) -- (keyboard_proc);
            \path [->,very thick,line,dashed] (buffer) -- (kcd);
            \path [->,very thick,line] (release) -- (kcd);
            \path [->,very thick,line] (keyboard_proc) -- (user_proc);
        \end{tikzpicture}
    \end{figure}

    \begin{algorithm}
        \caption{Uart Input Pseudocode}
        \label{code:uart_input}
        \begin{algorithmic}[1]
            \Function{\_\_asm UART0\_IRQHandler}{}
                \State \ldots
                \State BL c\_UART0\_IRQHandler
                \State \ldots
            \EndFunction
            \Function{c\_UART0\_IRQHandler}{}
                \State \ldots
                \State mark message as seen
                \State uart\_receive\_char\_isr(newChar);
                \State \ldots
            \EndFunction
            \Function{uart\_receive\_char\_isr}{newChar}
                \If{(writeIndex + 1) \% bufferSize == readIndex}
                    \State bufferOverflow = true
                    \State \Return
                \EndIf
                \State buffer[writeIndex] = newChar;
                \State writeIndex = (writeIndex + 1) % bufferSize
            \EndFunction
            \Function{releaseProcessor}{}
                \State \ldots
                \State processUartInput();
                \State \ldots
            \EndFunction
            \Function{processUartInput}{}
                \State \ldots
                \While{buffer has more}
                    \State char newChar = buffer[readIndex];
                    \State readIndex = (readIndex + 1) % bufferSize;
                    \If {newChar is a newline}
                        \State send a message to keyboard that a newline has occurred
                        \State continue;
                    \ElsIf{newChar is SHOW\_DEBUG\_PROCESSES}
                        \State print debug information, send it to the CRT proc
                        \State continue;
                    \EndIf
                \EndWhile
                \State \ldots
            \EndFunction
        \end{algorithmic}
    \end{algorithm}
\section{Output}
\subsection{Basic Output}
    At a basic level, user processes send messages to the CRT process, which
    buffers it into a stream. The method uart\_send\_char\_isr consumes the
    buffer and sends it through UART to the PuTTY on the PC. Additionally, the
    same UART0\_IRQHandler used in Section~\ref{sec:Input} triggers uart\_send\_char\_isr
    when the uart has notified us it is able to send more bytes. Diagram \ref{diagram:output} is a pictorial representation of a
    procedure that agrees with this description. In the next subsection
    \ref{sec:outputEnhancements}, we will explain how we exceeded the
    specifications which caused our implementation to be more complicated than
    this.

    \begin{figure}
        \centering
        \begin{tikzpicture}[node distance = 3cm, auto]
            \label{diagram:output}
            % Place nodes
            \node [block] (user_proc) {User Processes};
            \node [cloud, right of=user_proc] (message) {Message};
            \node [block, right of=message] (crtProc) {CRT process};
            \node [cloud, right of=crtProc] (buffer) {Buffer};
            \node [block, below of=crtProc] (handler) {UART Handler};
            \node [block, right of=handler] (sendChar) {sendCharIsr};
            \node [block, right of=sendChar] (uart) {UART};
            % Draw edges
            \path [very thick,line] (user_proc) -- (message);
            \path [->,very thick,line] (message) -- (crtProc);
            \path [->,very thick,line] (crtProc) -- (sendChar);
            \path [->,very thick,line,dashed] (crtProc) -- (buffer);
            \path [->,very thick,line,dashed] (buffer) -- (sendChar);
            \path [->,very thick,line] (handler) -- (sendChar);
            \path [->,very thick,line] (sendChar) -- (uart);
        \end{tikzpicture}
        \caption{Flow of Output Data to Uart}
    \end{figure}

\subsection{Output Enhancements}
\label{sec:outputEnhancements}
    We decided to implement a larger feature set than required in the
    application specification in order to make our PuTTY interface feel and act
    more like a command line found in a traditional computer. Our features
    include a text input bar that stays at the bottom while users type, coloured
    text, backspace support, and a few other enhancements.

    To achieve this, we've moved the buffered keyboard input into an envelope
    belonging to a CRTData object. Whenever the buffer is cleared by a
    user pressing the enter key, we move the cursor upwards, and write
    the content of the buffer in the cleared space. Similarly, if a process
    requests to print, we move the cursor upwards, and write the content of the
    message into the cleared space. By shifting the cursor's position, we are
    able to maintain the currently buffered user text at the bottom of the
    screen, allowing the user to see their text as they enter it. Implementing
    deletion only required parsing a special character in a similar way to a
    hot-key. Inside the pseudocode algorithm (\ref{code:uart_output}) listed for
    this subsection, the CRT process loads messages from the buffer that
    CRT\_advance loads with instructions to move characters, print content from
    processes, and show current input buffer status (i.e. what the user has
    typed).
    % ^Please verify this. I'm not entirely sure about how the two interact,
    % they're pretty coupled.


    \begin{algorithm}
        \caption{Uart Output Pseudocode}
        \label{code:uart_output}
        \begin{algorithmic}[1]
            \Function{CRT\_proc}{}
                \Loop
                    \State nextMessage = receive\_message(NULL)
                    \State pushEnvelope(nextMessage)
                    \While(crt\_hasData \&\& ((writeIndex + 1) % OUTPUT\_BUFSIZE != readIndex))
                        \State outputBuffer[writeIndex] = crt\_getData()
                        \State writeIndex = (writeIndex + 1) % OUTPUT\_BUFSIZE;
                    \EndWhile
                    \State uart\_send\_char\_isr(outputBuffer)
                \EndLoop
            \EndFunction
            \Function{CRT\_advance}{}
                \State Print the text bar. Remove characters that are not matching.

                \State Process output
                \While{hasQueuedEnvelopes}
                    \State Print next queued envelope until a null byte occurrs.
                \EndWhile

                \State move the cursor to the user position
            \EndFunction
        \end{algorithmic}
    \end{algorithm}



\chapter{Misc}
% Make sure to include pseudocode and testing, if appropriate.

\section{Bridge Layer}

\part{User-level Processes}

\chapter{Proc 1}

\chapter{Proc 2}

\part{Lessons Learned}
% They call this the lessons learned summary.
% 1-2 pages
% what you did do well, both technically and organizationally, and what you
% would do differently if you were to do it again

\end{document}
