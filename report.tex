\documentclass[12pt]{report}

% Packages (keep sorted)
\usepackage{
    algorithm,      % For algorithm environment
    algpseudocode,  % For pseudocode
    hyperref,       % For PDF bookmarks
    tikz,           % For state diagrams
}

% State diagrams (i.e. I/O)
\usetikzlibrary{
    shadows,
    positioning,
}
% TODO: move these to another file.
\tikzstyle{block} = [rectangle, draw,
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw]
\tikzstyle{cloud} = [draw, rectangle, node distance=3cm,
    minimum height=2em]

% PDF bookmarks setup (keep sorted)
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
}

\begin{document}

% Info section

% TODO(sanjay): come up with something more creative
\title{RTX Project Report}

\author{
    Craig, Shale\\
    20371384\\
    \texttt{sakcraig@uwaterloo.ca}
    \and
    Klen, Alex\\
    20372654\\
    \texttt{ayklen@uwaterloo.ca}
    \and
    Menakuru, Sanjay\\
    20374915\\
    \texttt{smenakur@uwaterloo.ca}
    \and
    Wei, Jonathan\\
    20376489\\
    \texttt{j25wei@uwaterloo.ca}
}

\maketitle

\begin{abstract}
    Here is our awesome abstract
\end{abstract}

\tableofcontents
\listofalgorithms
\listoffigures

% NOTE(sanjay): uncomment these if we add any figures or tables
% \listoftables


\part{Introduction}

\part{Kernel Implementation}
% This part is at max 30 pages.

\chapter{Scheduler}
% Make sure to include pseudocode and testing, if appropriate.

\section{Description}
    The scheduler is responsible for dividing processor time amongst all of the
    system's processes. It handles context switching between processes, deciding
    which process to schedule next, and preempting or blocking processes when
    appropriate. Processes can be in one of the following states: new, ready,
    running, blocked on memory, blocked on message, or unused. `New' is a state
    that processes are given after being initialized so that the scheduler can
    properly context switch to them for the first time. The running state
    signifies that the process is the only currently running process in the
    system. Processes which are ready are placed in a priority queue, and the
    scheduler will select the ready process with the highest priority to run
    next. Processes which are blocked on memory are put into another priority
    queue called the blocked-on-memory queue, and when memory is freed, the
    blocked process with the highest priority is unblocked. Processes that are
    blocked on a message remain blocked until they are sent a message.

    A process can be preempted when it frees memory or sends a message. If the
    process that it unblocks has a higher priority, then the currently running
    process is preempted.

    The ready queues are priority queues implemented using heaps. The decision
    was made to use a priority queue for all ready/blocked processes instead of
    a queue for each priority level because it allowed the system to support an
    arbitrary number of priorities without having the release\_processor runtime
    depend on the number of priorities.

    Pseudocode for process initialization is listed in Algorithm
    \ref{code:proc_init}.

    \begin{algorithm}
        \caption{Process Initialization Pseudocode}
        \label{code:proc_init}
        \begin{algorithmic}[1]
        \Function{k\_initProcesses}{}
            \State Initialize process-ready queue
            \State Initialize blocked-on-memory queue

            \For{each process p, index i}
                \State p.pid $\gets$ i
                \State p.stack $\gets$ \Call{acquireMemoryBlock}{} three times + memory block size \Comment{Use three memory blocks for each process stack and place stack pointer at end of third one}
                \State push initial required values onto stack
                \State set p.startLocation to appropriate process function location
                \Comment{Reserve a debug envelope for each process to be able to display a debug message even if there is no free memory in the system}
                \State p.debugEnvelope $\gets$ acquireMemoryBlock()
                \State p.state $\gets$ new
                \State add p to the process-ready queue
            \EndFor \\
            \State Initialize CRT proc
        \EndFunction
        \end{algorithmic}
    \end{algorithm}

    See Algorithm \ref{code:release_processor} for a pseudocode implementation
    for the kernel-level function k\_releaseProcessor. This function is called
    any time the current process should be preempted and a new process should be
    scheduled. The function takes a parameter that specifies what the reason is
    for the context switch. The release reason can be one of the following: a
    voluntary yield, a process priority change, memory was freed, the system is
    out of memory, a message was sent, or a message was received. The scheduling
    behavior can be different for some of these reasons.

\begin{algorithm}
    \caption{Release Processor Pseudocode}
    \label{code:release_processor}
    \begin{algorithmic}[1]
    \Function{k\_releaseProcessor}{releaseReason}
        \Comment{First we process the changed states of a few interrupt-driven systems here to avoid ISRs modifying kernel state while they are interrupting kernel methods}
        \State \Call{k\_processUartOutput}{}
        \State \Call{k\_processUartInput}{}
        \State \Call{k\_processDelayedMessages}{}

        \Comment{These variables are set depending on the release reason}
        \State define targetState, \Comment{The state to give the currently running process}
            \State \indent srcQueue, \Comment{The queue to schedule the next process
            from}
            \State \indent dstQueue \Comment{The queue to insert the current process into}

        \If{releaseReason = out of memory}
            \State srcQueue $\gets$ process-ready queue
            \State dstQueue $\gets$ blocked-on-memory queue
            \State targetState $\gets$ blocked on memory
        \ElsIf{releaseReason = message was received}
            \If{the current process's mail queue is empty}
                \State srcQueue $\gets$ process-ready queue
                \State dstQueue $\gets$ NULL \Comment{Don't place in any queue}
                \State targetState $\gets$ blocked on message
            \Else
                \State srcQueue $\gets$ process-ready queue
                \State dstQueue $\gets$ process-ready queue
                \State targetState $\gets$ ready
            \EndIf
        \Else
            \State srcQueue $\gets$ process-ready queue
            \State dstQueue $\gets$ process-ready queue
            \State targetState $\gets$ ready

            \If{currentProcess is the null process}
                \Comment{Keep the null process out of the ready queue - handle it separately}
                \State dstQueue $\gets$ NULL
            \EndIf
        \EndIf

        \If{srcQueue $\ne$ NULL and srcQueue.size $>$ 0}
            \State nextProc $\gets$ \Call{srcQueue.pop}{}
        \Else
            \State nextProc $\gets$ the null process
        \EndIf

    \algstore{releaseProcessor}
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \begin{algorithmic}[1]
    \algrestore{releaseProcessor}

        \If{currentProcess $\ne$ NULL}
            \Comment{Save old process info}
            \State currentProcess.stack $\gets$ \Call{getStackPointer}{}
            \State currentProcess.state $\gets$ targetState
            \If{dstQueue $\ne$ NULL}
                \State \Call{dstQueue.add}{currentProcess}
            \EndIf
        \EndIf

        \State oldState $\gets$ nextProc.state
        \State nextProc.state $\gets$ running
        \State currentProcess $\gets$ nextProc
        \State \Call{setStackPointer}{nextProc.stack}
        \If{oldState = new}
            \Call{\_\_rte}{} \Comment{If first time, pop the exception stack frame}
        \EndIf
    \EndFunction
    \end{algorithmic}
\end{algorithm}

\section{Running Time Analysis}

    The runtime for k\_initProcesses is $O(n\log n)$, where n is the number of
    processes in the system. This is because each processes is inserted into the
    process-ready queue, which is implemented as a heap and therefore taking
    $O(\log n)$ to insert an element. This function could be trivially modified
    to achieve a runtime of $O(n)$ time by putting all of the heap elements in
    an array first, and then heapifying it afterwards. Since there is a
    small, fixed number of processes in the system, this small optimization
    wasn't completed since this function only runs once at system startup.

    The runtime for k\_releaseProcessor, with the assumption that the UART and
    delayed message processing at the beginning will typically take $O(1)$ time,
    takes $O(\log n)$ time, where n is the number of processes in the system. It
    is bounded by removing and inserting from the source and destination
    priority queues (heaps). This provides good performance, and we can have an
    arbitrary number of priorities in the system because a priority queue was
    used instead of a queue per priority level.

\chapter{Memory Allocator}
% Make sure to include pseudocode and testing, if appropriate.

\section{Description}
    The memory allocator was designed with two orthogonal layers. The first is
    called the `block layer', and is responsible for allocating and deallocating
    blocks at a low level. The second is called the `metadata layer'; this layer
    builds upon the work done by the block layer, and adds the ability to store
    metadata about blocks. We will describe both of these layers independently.

\subsection{Block Layer}
    The block layer has a conceptually simple role. It is responsible for
    managing a pool of contiguous memory. Given a start memory address, an
    end memory address, and a block size, the block
    layer must provide two pieces of functionality. It must support allocating
    a block from the pool, and it must support freeing a block back into the
    pool. One design constraint is that it must prefer reusing a previously
    allocated block that has been freed, rather than handing out a block that
    has never been allocated before. The reason for this constraint will
    become clear when discussing the metadata layer.

    See Algorithm \ref{code:mem_block} for a pseudocode implementation of this
    layer. Note that this layer returns an error code when it runs out of
    memory. Further, this layer does some rudimentary sanity checking but
    doesn't handle some obvious error conditions. For example, this layer allows
    blocks to be inserted into the free list twice (assuming a trivial linked
    list implementation). This is not an error; it is the responsibility of
    the metadata layer to never allow this to happen. Finally, it is important
    to point out that this layer automatically zeroes memory. This is slightly
    detrimental to performance, but allows user processes to use binary
    comparisons between structs without caring about garbage in the struct's
    padding. We deemed this convenience worth the slight performance overhead.

    \begin{algorithm}
        \caption{Block layer pseudocode}
        \label{code:mem_block}
        \begin{algorithmic}[1]

            \State $blockSize \gets 2^7$
            \Comment{Blocksize in bytes (configurable)}

            \State $startAddr \gets 0$
            \Comment{Start address of pool (inclusive)}

            \State $endAddr \gets 2^{16}$
            \Comment{End address of pool (exclusive)}

            \State $nextAddr \gets startAddr$
            \Comment{Next available address in pool}

            \State $freeList \gets \{\}$
            \Comment{List of freed blocks}\\

            \Function{alloc\_block}{$ $}
                \If {$|freeList| > 0$} \Comment{Check free-list}
                    \State $blk \gets freeList[0]$
                    \State $freeList = freeList - \{blk\}$
                    \State \Call{zero}{$blk$}
                    \State \Return $blk$
                \EndIf\\

                \If {$nextAddr + blockSize >= endAddr$}
                    \Comment{Out-of-memory}
                    \State \Return $-1$
                \EndIf\\

                \State $blk \gets nextAddr$
                \State $nextAddr \gets nextAddr + blockSize$
                \State \Call{zero}{$blk$}
                \State \Return $blk$
            \EndFunction\\
            \Function{free\_block}{$blk$}
                \If {$blk < startAddr \vee nextAddr <= blk \vee endAddr <= blk$}
                    \State \Return \Comment{Outside valid range}
                \EndIf\\

                \If {$blk - startAddr \not\equiv 0 \bmod{blockSize}$}
                    \State \Return \Comment{Unaligned}
                \EndIf\\

                \State $freeList = freeList \cup \{blk\}$
            \EndFunction
        \end{algorithmic}
    \end{algorithm}


\subsection{Metadata Layer}
    The metadata layer builds atop the block layer, and adds the ability for the
    allocator to store metadata about blocks. Since it is built upon the block
    layer, it must fit its metadata storage in blocks. To avoid a costly setup
    phase, the metadata layer uses a lazy, arena-based storage scheme. The
    general version of the metadata layer supports an arbitrary amount of
    metadata per block ranging from some non-zero amount of metadata to half the
    block size worth of metadata.

    For the sake of description, let us call the number of metadata fields that
    fit inside a block $k$. That is to say, one block can hold the metadata for
    $k$ blocks. The metadata layer discriminates between two types of blocks,
    data blocks and arena header blocks. The metadata layer implements a
    function that takes a block and returns its associated arena header block.
    For our purposes, this function acts as the identity function when passed
    an arena header block. These definitions lead to the notion that an arena
    header block is responsible for storing the metadata of itself, as well as
    the following $k-1$ blocks. The metadata layer is responsible for serving
    the user-facing API.

    See Algorithm \ref{code:mem_meta} for a pseudocode implementation of this
    layer. Note that this layer can also access the variables defined by the
    block layer (they can be found in Algorithm \ref{code:mem_block}). Also
    note that we have elided the code of several trivial helper functions. For
    example, we did not specify the body of the `get\_header' function. Since
    the implementation of this function was some simple modular arithmetic, we
    did not feel it was worth wasting the reader's time with such minutiae.

    While the metadata layer is parameterized on $k$, for our actual
    implementation, we chose $k$ to be equal to our block size; this implies
    the metadata for each process fits inside 1 byte. Indeed, we stored the
    owner pid of each block as the only metadata, and the bitwidth of the pid
    type in our system was 8.

    \begin{algorithm}
        \caption{Metadata layer pseudocode}
        \label{code:mem_meta}
        \begin{algorithmic}[1]

            \State $k \gets 2^7$
            \Comment{Blocks per arena (configurable)}

            \State $arenaSize \gets k * blockSize$
            \Comment{Arena size (in bytes)}

            \Function{request\_memory\_block}{$pid$}
                \State $header \gets -1$
                \State $blk \gets -1$ \\

                \State $blk \gets \Call{alloc\_block}{ }$
                \If {$blk = -1$}
                    \State \Return $-1$
                \EndIf\\

                \State $header \gets \Call{get\_header}{blk}$
                \If {$blk = header$}
                    \State $blk \gets \Call{alloc\_block}{ }$
                \EndIf\\

                \If {$blk = -1$}
                    \State \Return $-1$
                \EndIf\\

                \State \Call{set\_owner}{$header, blk, pid$}
                \State \Return $blk$
            \EndFunction\\
            \Function{free\_memory\_block}{$blk, pid$}
                \State $header \gets \Call{get\_header}{blk}$
                \If {$header = -1$}
                    \State \Return $-1$
                \EndIf\\

                \If {$ \neg \Call{is\_owner}{header, blk, pid}$}
                    \State \Return $-1$
                \EndIf\\

                \State \Call{set\_owner}{$header, blk, 0$}
                \State \Call{free\_block}{$blk$}
            \EndFunction
        \end{algorithmic}
    \end{algorithm}


\section{Theoretical Analysis}
    Both layers were carefully designed to be $O(1)$ for all operations. This
    should be trivial by inspection, as all the functions do a tiny amount of
    arithmetic, and considering we used a linked-list as the implementation of
    the free list.

    A slightly more interesting analysis is the space overhead of our metadata
    scheme. The metadata layer uses $\frac{k-1}{k}$ blocks for storing user
    data; this yields a storage overhead of $\frac{1}{k}$. For our
    implementation, we picked $k=2^7$, yielding an overhead of $0.78\%$, or a
    utilization rate of $99.22\%$.

\section{Measurements}
    We profiled the performance of the memory allocator using the Keil IDE's
    built-in profiling tools. We found that on average the memory allocator
    would take $787.2 ns$ to return a fully zeroed memory block. This was
    determined by taking the average of 5 trials, where each trial did a few
    hundred calls to the allocation routine. The raw data from the trials can
    be found in Appendix \ref{appendix:raw_data}.

\chapter{Message Passing}
% Make sure to include pseudocode and testing, if appropriate.

\section{Description}

\section{Running Time Analysis}

\section{Measurements}

\chapter{I/O}
% Make sure to include pseudocode and testing, if appropriate.

    I/O interactions were designed to provide a simple user-facing interface
    while guaranteeing a high level of functionality and speed in low-memory
    situations. Functionality was split between separate input and output
    processes, each of which were responsible for providing their respective
    functionality. By separating functionality, we were able to take advantage
    of the benefits of microkernel architecture instead of monolithic
    architecture.
    In the context of our OS, both input and output tasks consisted of % TODO: should I put our OS name here?
    interacting solely with UART (Universal Asynchronous Receiver / Transmitter)
    connections to the boards used in this lab.
    We will describe both input and output independently in their respective
    sections.

\section{Input}
\label{sec:Input}
    In this assignment, the primary input device is keyboard input.
    Keyboard input triggers the UART0\_IRQHandler assembly interrupt. This
    passes the input to the c\_UART0\_IRQHandler method that puts the events
    in a buffer. Whenever release\_processor is called, messages in the
    buffer are sent to the keyboard decoder method to decode the new
    events in the buffer. In the case that input is a hot-key,
    it immediately executes the relevant execution path. In the case that input
    is a complete command, a process that has registered for that command will
    receive a message containing the command. If no processes have been
    registered, the message is freed.

    Figure \ref{fig:inputFigure} illustrates this process in a visually
    apparent manner, and Algorithm \ref{code:uart_input} expresses this flow
    algorithmically.

    \begin{figure}
        \centering
        \caption{Flow of Input Data to User Processes}
        \label{fig:inputFigure}
        \begin{tikzpicture}[node distance = 3cm,
                            auto]
            % Place nodes
            \node [block] (kbd) {keyboard};
            \node [cloud, above of=kbd] (user) {user};
            \node [block, right of=kbd] (uart_h) {IRQHandler};
            \node [cloud, above right of=uart_h] (buffer) {buffer};
            \node [block, right of=uart_h] (kcd) {keyboard decoder};
            \node [block, below of=kcd] (release) {release processor};
            \node [cloud, right of=kcd] (message) {message};
            \node [block, right of=message] (keyboard_proc) {keyboard process};
            \node [block, below of=keyboard_proc] (user_proc) {user processes};
            % Draw edges
            \path [->,very thick,line,dashed] (user) -- (kbd);
            \path [->,very thick,line] (kbd) -- (uart_h);
            \path [->,very thick,line,dashed] (uart_h) -- (buffer);
            \path [->,very thick,line] (release) -- (kcd);
            \path [very thick,line] (kcd) -- (message);
            \path [->,very thick,line] (message) -- (keyboard_proc);
            \path [->,very thick,line,dashed] (buffer) -- (kcd);
            \path [->,very thick,line] (release) -- (kcd);
            \path [->,very thick,line] (keyboard_proc) -- (user_proc);
        \end{tikzpicture}
    \end{figure}

    \begin{algorithm}
        \caption{Uart Input Pseudocode}
        \label{code:uart_input}
        \begin{algorithmic}[1]
            \Function{\_\_asm UART0\_IRQHandler}{}
                \State \ldots
                \State BL c\_UART0\_IRQHandler
                \State \ldots
            \EndFunction
            \Function{c\_UART0\_IRQHandler}{}
                \State \ldots
                \State mark message as seen
                \State uart\_receive\_char\_isr(newChar);
                \State \ldots
            \EndFunction
            \Function{uart\_receive\_char\_isr}{newChar}
                \If{(writeIndex + 1) \% bufferSize == readIndex}
                    \State bufferOverflow = true
                    \State \Return
                \EndIf
                \State buffer[writeIndex] = newChar;
                \State writeIndex = (writeIndex + 1) % bufferSize
            \EndFunction
            \Function{releaseProcessor}{}
                \State \ldots
                \State processUartInput();
                \State \ldots
            \EndFunction
            \Function{processUartInput}{}
                \State \ldots
                \While{buffer has more}
                    \State char newChar = buffer[readIndex];
                    \State readIndex = (readIndex + 1) % bufferSize;
                    \If {newChar is a newline}
                        \State send a message to keyboard that a newline has occurred
                        \State continue;
                    \ElsIf{newChar is SHOW\_DEBUG\_PROCESSES}
                        \State print debug information, send it to the CRT proc
                        \State continue;
                    \EndIf
                \EndWhile
                \State \ldots
            \EndFunction
        \end{algorithmic}
    \end{algorithm}
\section{Output}
\subsection{Basic Output}
    At a basic level, user processes send messages to the CRT process, which
    buffers it into a stream. The method uart\_send\_char\_isr consumes the
    buffer and sends it through UART to the PuTTY on the PC. Additionally, the
    same UART0\_IRQHandler used in Section~\ref{sec:Input} triggers
    uart\_send\_char\_isr when the uart has notified us it is able to send more
    bytes. Figure \ref{fig:outputFigure} is a pictorial representation of this
    procedure. In the next subsection
    \ref{sec:outputEnhancements}, we will explain how we exceeded the
    specifications which caused our implementation to be more complicated than
    this.

    \begin{figure}
        \centering
        \label{fig:outputFigure}
        \begin{tikzpicture}[node distance = 3cm, auto]
            % Place nodes
            \node [block] (user_proc) {User Processes};
            \node [cloud, right of=user_proc] (message) {Message};
            \node [block, right of=message] (crtProc) {CRT process};
            \node [cloud, right of=crtProc] (buffer) {Buffer};
            \node [block, below of=crtProc] (handler) {UART Handler};
            \node [block, right of=handler] (sendChar) {sendCharIsr};
            \node [block, right of=sendChar] (uart) {UART};
            % Draw edges
            \path [very thick,line] (user_proc) -- (message);
            \path [->,very thick,line] (message) -- (crtProc);
            \path [->,very thick,line] (crtProc) -- (sendChar);
            \path [->,very thick,line,dashed] (crtProc) -- (buffer);
            \path [->,very thick,line,dashed] (buffer) -- (sendChar);
            \path [->,very thick,line] (handler) -- (sendChar);
            \path [->,very thick,line] (sendChar) -- (uart);
        \end{tikzpicture}
        \caption{Flow of Output Data to Uart}
    \end{figure}

\subsection{Output Enhancements}
\label{sec:outputEnhancements}
    We decided to implement a larger feature set than required in the
    application specification in order to make our PuTTY interface feel and act
    more like a command line found in a traditional computer. Our features
    include a text input bar that stays at the bottom while users type, coloured
    text, backspace support, and a few other enhancements.

    To achieve this, we've moved the buffered keyboard input into an envelope
    belonging to a CRTData object. Whenever the buffer is cleared by a
    user pressing the enter key, we move the cursor upwards, and write
    the content of the buffer in the cleared space. Similarly, if a process
    requests to print, we move the cursor upwards, and write the content of the
    message into the cleared space. By shifting the cursor's position, we are
    able to maintain the currently buffered user text at the bottom of the
    screen, allowing the user to see their text as they enter it. Implementing
    deletion only required parsing a special character in a similar way to a
    hot-key. Inside the pseudocode algorithm (\ref{code:uart_output}) listed for
    this subsection, the CRT process loads messages from the buffer that
    CRT\_advance loads with instructions to move characters, print content from
    processes, and show current input buffer status (i.e. what the user has
    typed).
    % ^Please verify this. I'm not entirely sure about how the two interact,
    % they're pretty coupled.


    \begin{algorithm}
        \caption{Uart Output Pseudocode}
        \label{code:uart_output}
        \begin{algorithmic}[1]
            \Function{CRT\_proc}{}
                \Loop
                    \State nextMessage = receive\_message(NULL)
                    \State pushEnvelope(nextMessage)
                    \While(crt\_hasData \&\& ((writeIndex + 1) % OUTPUT\_BUFSIZE != readIndex))
                        \State outputBuffer[writeIndex] = crt\_getData()
                        \State writeIndex = (writeIndex + 1) % OUTPUT\_BUFSIZE;
                    \EndWhile
                    \State uart\_send\_char\_isr(outputBuffer)
                \EndLoop
            \EndFunction
            \Function{CRT\_advance}{}
                \State Print the text bar. Remove characters that are not matching.

                \State Process output
                \While{hasQueuedEnvelopes}
                    \State Print next queued envelope until a null byte occurrs.
                \EndWhile

                \State move the cursor to the user position
            \EndFunction
        \end{algorithmic}
    \end{algorithm}



\chapter{Misc}
% Make sure to include pseudocode and testing, if appropriate.

\section{Bridge Layer}

\subsection{Description}
    We added a bridge layer in order to allow our user processes to access the
    kernel-level functions safely.  These bridging functions allow us to pass
    global data structures into the kernel functions, as well as do additional
    validation or work that only needs to be done when a user process calls the
    function as opposed to when it is called from within kernel space.

    Examples of this where additional functionality was added are listed below.

    \begin{description}
        \item [acquireMemoryBlock] We want this to be a blocking call when
            the system is out of memory, so we loop in the bridge function.  We
            alternate between calling the k\_acquireMemoryBlock function (which
            will return an error code if there is no memory left) and calling
            k\_releaseProcessor until the user process successfully obtains a
            block.
        \item [releaseMemoryBlock] If there are processes that are blocked on
            memory, then the highest priority process should receive the
            released memory block.  The highest priority blocked process is
            placed back into the ready queue, and we preempt the current process
            if the blocked process is of higher priority.
        \item [sendMessage] The sending process is preempted if the message sent
            unblocks a process of higher priority.  This is done here so we
            guarantee that we only call k\_releaseProcessor if it was a user
            process of lower priority that made the sendMessage call.
        \item [receiveMessage] The output parameter is set here, if available.
    \end{description}

\section{Get/Set Priority}

\subsection{Description}
    These functions return and set priorities of processes, respectively.
    Validation is done to ensure that only proper process IDs and priorities are
    passed in.  k\_setProcessPriority will preempt the currently running process
    if it is of lower priority.

    k\_get\_process\_priority simply verifies if the passed process ID is valid
    and returns the priority of that process, or -1 otherwise.  As
    k\_set\_process\_priority is more complicated, its pseudocode has been
    included under Algorithm \ref{code:set_process_priority}.

    There are two helper functions used: setMaskPriority and pqChangedPriority.
    setMaskPriority sets the new priority to retain the old priority's leading
    bits, while setting its last 7 bits to the desired priority.
    pqChangedPriority modifies the given process' priority in the queue and
    rebalances the backing heap to keep it in sorted order.

    Overall, this function takes at most $O(\log(n))$ time where $n$ is the
    number of processes in the queue that the process whose priority is being
    changed resides in.  All other operations in the function are constant time.

    \begin{algorithm}
        \caption{Kernel set process priority pseudocode}
        \label{code:set_process_priority}
        \begin{algorithmic}[1]

            \Function{k\_setProcessPriority}{$pid, priority$}
                \State $modifiedProcess \gets \Call {k\_getPCB}{pid}$\\
                \Comment {Returns NULL if pid is invalid}

                \If {$modifiedProcess = NULL \mid\mid modifiedProcess = nullProcess$}
                    \State \Return {$EINVAL$}
                \EndIf\\

                \State \Call {setMaskPriority}{$modifiedProcess, oldPriority,
                    newPriority$}
                \Comment {Set the priority to the masked new priority}\\

                \State \Call {pqChangedPriority}{$readyQueue, memoryQueue,
                    modifiedProcess$}
                \Comment {Change priority state in the queues, safe to call if
                    the process isn't in the queue}\\

                \If {$we\ improved\ our\ own\ priority\ or\ top\ process\ has\
                    same\ or\ worse\ priority$}
                    \State \Return {$SUCCESS$}
                    \Comment {Don't preempt ourselves}
                \EndIf\\

                \State \Call {k\_releaseProcessor}{$CHANGED\_PRIORITY$}\\

                \State \Return {$SUCCESS$}
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

\part{User-level Processes}

\chapter{Set Priority Command Process}

\section{Description}
    This process is responsible for allowing the user to change process
    priorities through terminal commands.  It is registered to the \%C command,
    and will attempt to set a new priority level to the given process ID.
    Validation is done on the input parameters to ensure that they are actually
    valid inputs before calling set\_process\_priority(pid, priority).  We check
    to ensure that we have a space between \%C, the pid, and the priority.  We
    also ensure that the pid is valid (within our allowed range of integers) and
    that the priority is valid (between 0 and 255 inclusive).  The
    set\_process\_priority process itself satisfies the requirements that the
    change be immediate and that the target process could be located in the
    ready or blocked resource queue.

    See Algorithm \ref{code:user_set_priority} for a pseudocode implementation
    of this user process.  Note that this process, among others, makes use of
    a custom implementation of a read\_uint32 helper function that we created.
    The pseudocode for that function is included in Algorithm
    \ref{code:read_uint32}.

    As a user process, we require memory in order to send a message to it (as
    the user), so we will be unable to send commands to it (as well as other
    user processes) in a situation where we are out of memory.  Therefore, we
    are unable to use this process to stop a misbehaving process that is holding
    and not releasing memory if we are already out of memory.

    \begin{algorithm}
        \caption{Set priority command process pseudocode}
        \label{code:user_set_priority}
        \begin{algorithmic}[1]
            \Function {setPriorityProcess}{}
                \State $envelope \gets \Call {request\_memory\_block}{}$
                \State \Call {init\_registration\_envelope}{$envelope, c$}
                \State \Call {send\_message}{$KEYBOARD\_PID, envelope$}\\

                \Loop
                    \State $envelope \gets \Call {receive\_message}{NULL}$\\

                    \If {$envelope \rightarrow srcPid \ne KEYBOARD\_PID$}
                        \State \Call {release\_memory\_block}{$envelope$}
                        \State $continue$
                    \EndIf\\

                    \If {$envelope\ message\ isn't\ prefixed\ with\ \%C$}
                        \State \Call {release\_memory\_block}{$envelope$}
                        \State $continue$
                    \EndIf\\

                    \State $status \gets \Call {processSetMessage}{envelope
                        \rightarrow message}$
                    \Comment {This will also call set\_process\_priority if the
                        contents pass validation}

                    \If {$status = EINVAL$}
                        \Comment {Print error message upon failure to validate}
                        \State \Call {printSetErrorMessage}{$envelope$}
                    \Else
                        \State \Call {release\_memory\_block}{$envelope$}
                    \EndIf
                \EndLoop
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

    \begin{algorithm}
        \caption{Read uint32 from char array pseudocode}
        \label{code:read_uint32}
        \begin{algorithmic}[1]
            \Function {read\_uint32}{$buf, out$}
                \Comment {buf is a char pointer}
                \State $number \gets 0$
                \Comment {The integer result}
                \State $read \gets 0$
                \Comment {Number of characters read}\\

                \If {$buf = NULL$}
                    \State \Return $0$
                    \Comment {Return if there's nothing to read}
                \EndIf\\

                \While {$read < \Call{len}{buf}$}
                    \If {\Call {$\neg$is\_numeric}{$buf \lbrack 0 \rbrack$}}
                        \State \textbf{break}
                    \EndIf\\

                    \State $number \gets number \times 10$
                    \State $number \gets number + \Call {to\_int}{buf \lbrack 0 \rbrack}$
                    \State $read \gets read + 1$
                    \State $buf \gets buf + 1$
                \EndWhile\\

                \If {$out \ne NULL$}
                    \State $out \lbrack 0 \rbrack \gets number$
                \EndIf\\

                \State \Return $read$
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

\chapter{24-Hour Wall Clock Display Process}

\section{Description}
    This process is responsible for acting as a digital clock, printing the time
    at one second intervals.  The user can start the clock at 00:00:00 with the
    command \%WR, can stop output with \%WT, and can set an arbitrary time using
    \%WS HH:MM:SS.  The process will reject any messages passed to it that
    either don't begin with the registered \%W command, or are malformed.

    For the \%WS HH:MM:SS command, we check that there is a space in between
    \%WS and HH:MM:SS.  As well, we make sure that there are colons in between
    HH, MM, and SS.  We also ensure that HH is between 00 and 23 inclusive, and
    MM and SS are both between 00 and 59 inclusive.

    See Algorithm \ref{code:user_clock} for a pseudocode implementation
    of this user process.  Note that this process, among others, makes use of
    a few helper functions.  It uses read\_uint32, write\_uint32, as well as
    write\_string.  See Algorithm \ref{code:write_uint32} for the pseudocode of
    write\_uint32, and Algorithm \ref{code:write_string} for the pseudocode of
    write\_string.  In addition, a user API call get\_time is also used.  This
    simply obtains the current system counter, which is incremented every
    millisecond by the timer ISR.

    \begin{algorithm}
        \caption{Wall clock process pseudocode}
        \label{code:user_clock}
        \begin{algorithmic}[1]
            \State $receivedEnvelope \gets NULL$
            \Comment {Envelope for message passing}
            \State $selfEnvelope \gets \Call {request\_memory\_block}{}$
            \Comment {Cached envelope for self delayed messages}
            \State $cmdType \gets TERMINATE$
            \Comment {Action to take}
            \State $currentTime \gets 0$
            \Comment {Cached current time}
            \State $offset \gets 0$
            \Comment {Offset for calculating time}
            \State $isRunning \gets 0$
            \Comment {Boolean value for running state}\\

            \Function {parseClockMessage}{}
                \State $status \gets 0$
                \State $envelope \gets receivedEnvelope$\\

                \If {$envelope \rightarrow srcPid = CLOCK\_PID$}
                    \Comment {Received wake up, don't release memory}
                    \If {$isRunning$}
                        \Comment {If not terminated, print time}
                        \State $cmdType \gets PRINT\_TIME$
                    \EndIf
                    \State \Return
                \ElsIf {$envelope \rightarrow srcPid \ne KEYBOARD\_PID}$
                    \Comment {Ignore unwanted message}
                    \State \Call {release\_memory\_block}{$envelope$}
                    \State \Return
                \EndIf\\

                \If {$envelope \rightarrow message \lbrack 2 \rbrack = $`R'}
                    \State $cmdType \gets RESET\_TIME$
                \ElsIf {$envelope \rightarrow message \lbrack 2 \rbrack = $`T'}
                    \State $cmdType \gets TERMINATE$
                \ElsIf {$envelope \rightarrow message \lbrack 2 \rbrack = $`S'}
                    \State $cmdType \gets SET\_TIME$
                \Else
                    \State \Return
                \EndIf\\

                \If {$cmdType = RESET\_TIME$}
                    \State $offset \gets -1 \times currentTime$
        \algstore{wallClockProcess}
        \end{algorithmic}
    \end{algorithm}

    \begin{algorithm}
        \begin{algorithmic}[1]
        \algrestore{wallClockProcess}
                    \If {$isRunning = 0$}
                        \Comment {Start clock if necessary}
                        \State $cmdType \gets PRINT\_TIME$
                    \EndIf
                \ElsIf {$cmdType = SET\_TIME$}
                    \State $status, offset \gets \Call {parseTime}{envelope}$
                        \Comment {Sets offset if validation is passed}
                    \If {$status = SUCCESS \&\& isRunning = 0$}
                        \Comment {Start clock if necessary}
                        \State $cmdType \gets PRINT\_TIME$
                    \EndIf
                \ElsIf {$cmdType = TERMINATE$}
                    \State $isRunning \gets 0$
                \EndIf\\

                \State \Call {release\_memory\_block}{$envelope$}
            \EndFunction\\

            \Function {clockProcess}{}
                \State $envelope \gets \Call {request\_memory\_block}{}$
                \State \Call {init\_registration\_envelope}{$envelope, w$}
                \State \Call {send\_message}{$KEYBOARD\_PID, envelope$}\\

                \Loop
                    \State $receivedEnvelope \gets \Call {receive\_message}{}$
                    \State $currentTime \gets \Call {get\_time}{}$\\

                    \State \Call {parseClockMessage}{}\\

                    \If {$cmdType = PRINT\_TIME$}
                        \Comment {Print the time in HH:MM:SS using the
                            calculated offset, and wake self in 1 second}
                        \State \Call {printTime}{$currentTime, offset$}
                        \State $isRunning \gets 1$
                        \State \Call {delayed\_send}{$CLOCK\_PID, selfEnvelope,
                            1000$}
                    \EndIf
                \EndLoop
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

    \begin{algorithm}
        \caption{Write uint32 to char array pseudocode}
        \label{code:write_uint32}
        \begin{algorithmic}[1]

            \Function{write\_uint32}{$buf, number, minDigits$}
                \Comment {buf is a char pointer}
                \State $tempNumber \gets number$
                \State $numDigits \gets 0$
                \Comment {Number of digits available}\\

                \While {$tempNumber > 0$}
                    \State $numDigits \gets numDigits + 1$
                    \State $tempNumber \gets tempNumber / 10$
                \EndWhile\\

                \If {$minDigits < 1$}
                    \State $minDigits \gets 1$
                \EndIf\\

                \If {$numDigits < minDigits$}
                    \State $numDigits \gets minDigits$
                \EndIf\\

                \If {$numDigits > \Call {len}{buf}$}
                    \State $numDigits \gets \Call {len}{buf}$
                \EndIf\\

                \State $tempNumber \gets numDigits$\\

                \While {$numDigits > 0$}
                    \If {$buf \ne NULL$}
                        \State $buf \lbrack numDigits - 1 \rbrack \gets \Call
                            {to\_char}{number \% 10}$
                    \EndIf\\

                    \State $number \gets number / 10$
                    \State $numDigits \gets numDigits - 1$
                \EndWhile\\

                \State \Return $tempNumber$
                \Comment {Returns number of digits read}
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

    \begin{algorithm}
        \caption{Write string to char array pseudocode}
        \label{code:write_string}
        \begin{algorithmic}[1]

            \Function{write\_string}{$buf, message$}
                \Comment {buf is a char pointer}
                \State $written \gets 0$
                \Comment {Number of characters written}
                \State $bufLen \gets \Call {len}{buf}$\\

                \If {$msg = NULL$}
                    \State \Return $0$
                    \Comment {Return if there's nothing to write}
                \EndIf\\

                \While {$msg \lbrack 0 \rbrack \ne NULL\_CHAR \&\&
                    bufLen > 0$}
                    \If {$buf \ne NULL$}
                        \State $buf \lbrack 0 \rbrack \gets msg \lbrack 0
                            \rbrack$
                        \State $buf \gets buf + 1$
                    \EndIf\\

                    \State $msg \gets msg + 1$
                    \State $bufLen \gets bufLen - 1$
                    \State $written \gets written + 1$
                \EndWhile\\

                \State \Return $written$
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

\chapter{Stress Processes A, B, and C}

\section{Description}
    These processes were used to stress test the system.  Process A was
    registered under command \%Z.  Upon starting, it would continuously obtain
    a memory block when possible and send it off as a message to process B,
    containing the value of a counter that it incremented every time it went
    around the loop.  Process B would redirect any messages to process C.
    Process C had its own extra message queue (on top of the one that we already
    had for each process).  If there was something in its extra queue, we would
    dequeue from that first, before processing any new messages from its regular
    queue.  Then, if we received a message from process A, we would check if the
    counter that was included is divisible by 20.  If so, we send a message to
    the CRT process to print a message to the screen, then sleep for 10 seconds.
    During this time, messages from process A (through process B) would continue
    to accumulate, eventually running out of memory when there is none left to
    use to send messages.  After waking up, C would process all the messages in
    the queue, releasing their memory, and the cycle would begin again.

    This set of operations would quickly deprive our system of memory.  It was
    designed to see how the system would respond in a no-memory situation.  When
    we ran this during testing, we would run into deadlocks in the situation
    when the priority of process C was less than or equal to process A, as
    process A only requested memory blocks, while process C was the one that
    released memory.  The scenario would be when all the memory is locked up
    inside process C's local message queue, and it blocks during the call to
    sleep (which requires an envelope in order to send itself a message).  To
    this end, we modified the sleep function such that this scenario wouldn't
    occur.  We would still be out of memory, but we wouldn't deadlock - we
    would simply undergo the 10 second cycle of flushing all memory, then being
    out of memory again until the next time process C wakes up.

    To do this, we preallocated envelopes for processes that needed to use the
    sleep function (process C as well as some of our own user-level test
    processes).  That way, sleep doesn't require a call to
    request\_memory\_block, so it's a non-blocking call (apart from the sleep
    itself).

    The pseudocode for processes A, B, and C are not included as they were
    implemented off of the given pseudocode in the project description.
    However, an additional envelope was preallocated for process C so that its
    sleep call wouldn't block.  See Algorithm \ref{code:sleep} for a pseudocode
    implementation of the sleep function, which was modified from the given
    pseudocode in order to include our additional functionality.  We also make a
    user call to pid(), which is a function returning the process ID of the
    currently running process.

    \begin{algorithm}
        \caption{Sleep function pseudocode}
        \label{code:sleep}
        \begin{algorithmic}[1]
            \Function {sleep}{$ms, listEnv, sleepEnv$}
                \Comment {listEnv is a double pointer to Envelope to be used as
                    an additional message queue, while sleepEnv is a pointer to
                    a preallocated Envelope to be used for sending the delayed
                    message}
                \State $currentTime \gets \Call {get\_time}{}$
                \State $targetTime \gets currentTime + ms$
                \State $sleepEnv \rightarrow messageType \gets MT\_SLEEP$
                \State \textproc {delayed\_send}(\Call {pid}{}$, sleepEnv,
                    targetTime - currentTime$)\\

                \If {$listEnv \ne NULL$}
                    \Comment {Advance to back of passed queue if available}
                    \While {$listEnv \lbrack 0 \rbrack \ne NULL$}
                        \State $listEnv \gets \Call {addrOf}{listEnv \lbrack 0
                            \rbrack \rightarrow next}$
                    \EndWhile
                \EndIf\\

                \Loop
                    \State $env \gets \Call {receive\_message}{}$\\

                    \If {$env \rightarrow messageType = MT\_SLEEP$}
                        \Comment {If it's the sleep message, then we can wake
                            up}
                        \State \Return
                    \ElsIf {$listEnv \ne NULL$}
                        \Comment {Push onto queue if available}
                        \State $env \rightarrow next \gets NULL$
                        \State $listEnv \lbrack 0 \rbrack \gets env$
                        \State $listEnv \gets \Call {addrOf}{env \rightarrow
                            next}$
                    \Else
                        \Comment {Send it to ourselves on a delay to process
                            later otherwise}
                        \State \textproc {delayed\_send}(\Call {pid}{}$, env,
                            ms$)
                    \EndIf
                \EndLoop
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

\chapter{User-Level Test Processes}

\section{Description}

    We had various user-level processes that we created for the first
    deliverable, and continued to use throughout creating our OS.  As we
    continued adding more features, the user processes were modified as well.
    Most notably, they were modified in order to incorporate a sleep function,
    which we had already implemented for the second deliverable after adding
    message passing.  As we set the processes to sleep for different delays, it
    is possible to see the interleaving of message printing by the CRT process
    when their delays synchronise.  The processes are listed below.

\subsection{`funProcess'}

    This process would send 5 messages to the CRT process to print the numbers
    1, 2, 3, 4, and 5.  It would then sleep for 3000 milliseconds.  This would
    be repeated indefinitely.  This process, along with the other processes, had
    to be modified for the second deliverable when we switched from straight
    UART polling to passing messages to the CRT process for printing.

\subsection{`schizophrenicProcess'}

    This process is similar to `funProcess', printing the numbers 9, 8, 7, 6,
    and 5.  It would then sleep for 4000 milliseconds.  This would be repeated
    indefinitely.

\subsection{`fibProcess'}

    This process would print the first 40 or so Fibonacci numbers.  It would
    print these 5 at a time, then sleep for 1000 milliseconds.  After reaching
    the Fibonacci number just under 1000000000, it would restart at 1.  This
    would be repeated indefinitely.

\subsection{`memoryMuncherProcess'}

    This process would request all available memory blocks, printing the
    addresses of the obtained memory blocks.  When it has obtained all available
    blocks, it would try to acquire another block, which would cause the process
    to block, waiting for an additional memory block to become available.  Prior
    to this, it would set the priority of `releaseProcess' to the highest
    possible, which would free a preallocated block of memory, allowing this
    process to continue.  After becoming unblocked, it would free all held
    memory blocks and then block on receiving a message indefinitely.

\subsection{`releaseProcess'}

    This process was used in conjunction to the above `memoryMuncherProcess'.
    At startup, this process had the highest priority.  It would preallocate a
    memory block (used to unblock `memoryMuncherProcess'), then set its own
    priority to the lowest possible.  It would then call release\_processor.
    Our other user processes were running at higher priority than this one was
    set to, so it would require a set\_process\_priority in order to get it to
    run again, provided by `memoryMuncherProcess'.  It would continue executing
    after having its priority set to the highest possible again by
    `memoryMuncherProcess', and free its single block.  After doing so, it would
    block on receiving a message indefinitely.  The combination of these two
    processes allowed us to test low to no memory situations to ensure our
    memory allocator was working as expected, as well as to ensure that our
    APIs for setting and getting priorities were working correctly.

\part{Lessons Learned}
% They call this the lessons learned summary.
% 1-2 pages
% what you did do well, both technically and organizationally, and what you
% would do differently if you were to do it again

\end{document}
